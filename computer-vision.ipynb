{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Test.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenieto/computer-vision/blob/normalize-scikit-learn/computer-vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nzKF921nSpb",
        "colab_type": "text"
      },
      "source": [
        "Trabajo M0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuG171gUnSpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Montamos Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!unzip -o \"/content/drive/My Drive/Datasets/computer-vision-M2.zip\" -d /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8WL4YNeGAkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importamos librerias\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhYCoKhyGqi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definimos variables\n",
        "csv_path = '/content/computer-vision-M2/anotaciones_itemsEvaluables_v3.csv'\n",
        "images_path = '/content/computer-vision-M2/dataset1'\n",
        "figure = 'a1'\n",
        "target_shape = (128, 128, 1)\n",
        "test_dataset_size = 0.25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz1nGW1upVDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funciones para leer los datos\n",
        "def read_csv_data():\n",
        "  data = pd.read_csv(csv_path, sep=';', names=['dir', 'image', 'figure', 'coords'], index_col=False, skipinitialspace=True)\n",
        "  for key in data.keys():\n",
        "    data[key] = data[key].apply(str.replace, args=(' ', ''))\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hvEx6y4Idud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Leemos los datos\n",
        "data = read_csv_data()\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0GLzUrYKBlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inicializamos una intancia scaler\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "# Funcion para leer una imagen y sus coordenadas\n",
        "def read_sample(row, type=0, n_points=1):\n",
        "  # Leer imagen\n",
        "  path = os.path.join(images_path, 'grafos_' + row['dir'], 'grafo_' + row['image'] + '.png')\n",
        "  raw_X = cv2.imread(path,0)\n",
        "  raw_y = None\n",
        "  proc_X = None\n",
        "  proc_y = None\n",
        "  if raw_X is not None: # TODO: algunas imagenes no existen\n",
        "    shape = raw_X.shape\n",
        "    raw_X_1 = raw_X[:shape[0]//2, :shape[1]//2] # Imagen original\n",
        "    raw_X_2 = raw_X[:shape[0]//2, shape[1]//2:] # Imagen original invertida\n",
        "    raw_X_3 = raw_X[shape[0]//2:, :shape[1]//2] # Imagen de grafos detalle alto\n",
        "    raw_X_4 = raw_X[shape[0]//2:, shape[1]//2:] # Imagen de grafos detalle bajo\n",
        "    subimage_shape = raw_X_1.shape\n",
        "    raw_X_1 = cv2.resize(raw_X_1, dsize=(target_shape[0], target_shape[1]))\n",
        "    raw_X_2 = cv2.resize(raw_X_2, dsize=(target_shape[0], target_shape[1]))\n",
        "    raw_X_3 = cv2.resize(raw_X_3, dsize=(target_shape[0], target_shape[1]))\n",
        "    raw_X_4 = cv2.resize(raw_X_4, dsize=(target_shape[0], target_shape[1]))\n",
        "    proc_X_1 = scaler.fit_transform(raw_X_1) # Opción más simple: raw_X_1 / 255\n",
        "    proc_X_2 = scaler.fit_transform(raw_X_2) # Opción más simple: raw_X_2 / 255\n",
        "    proc_X_3 = scaler.fit_transform(raw_X_3) # Opción más simple: raw_X_3 / 255\n",
        "    proc_X_4 = scaler.fit_transform(raw_X_4) # Opción más simple: raw_X_4 / 255\n",
        "    if type == 0:\n",
        "      raw_X = raw_X_2 # Sólo se usa la imagen original invertida\n",
        "      proc_X = proc_X_2\n",
        "    elif type == 1:\n",
        "      raw_X = np.stack((raw_X_2, raw_X_3), axis=-1) # Se usa imagen original invertida + grafos alto detalle\n",
        "      proc_X = np.stack((proc_X_2, proc_X_3), axis=-1)\n",
        "    elif type == 2:\n",
        "      raw_X = np.stack((raw_X_2, raw_X_3, raw_X_4), axis=-1) # Se usa imagen original invertida + grafos alto detalle + grafos bajo detalle\n",
        "      proc_X = np.stack((proc_X_2, proc_X_3, proc_X_4), axis=-1)\n",
        "    raw_X = np.expand_dims(raw_X, axis=0)\n",
        "    proc_X = np.expand_dims(proc_X, axis=0)\n",
        "    # Leer coordenadas\n",
        "    flat = np.array([int(s) for s in re.findall('\\d+', row['coords'])]) # Parsea los números en el texto\n",
        "    mat = flat.reshape((-1, 2)) # Reagrupa las coordenadas en grupos de dos\n",
        "    if mat.shape[0] >= n_points:\n",
        "      mat = mat[:n_points, :] * 2 # Las coordenadas vienen divididas entre 2\n",
        "      raw_y = (mat * np.array([target_shape[0] / subimage_shape[0], target_shape[1] / subimage_shape[1]])).flatten()\n",
        "      proc_y = raw_y / np.array([target_shape[0], target_shape[1]])\n",
        "      raw_y = np.expand_dims(raw_y, axis=0)\n",
        "      proc_y = np.expand_dims(proc_y, axis=0)\n",
        "  return raw_X, raw_y, proc_X, proc_y\n",
        "\n",
        "# Funcion que devuelve las imagenes y las coordenadas\n",
        "def read_data(data):\n",
        "  firstIteration = True\n",
        "  for _, row in data.iterrows():\n",
        "    raw_X, raw_y, proc_X, proc_y = read_sample(row, 2)\n",
        "    if firstIteration == True:\n",
        "      images = raw_X\n",
        "      labels = raw_y\n",
        "      X = proc_X\n",
        "      y = proc_y\n",
        "      firstIteration = False\n",
        "    elif raw_X is not None and raw_y is not None:\n",
        "      images = np.concatenate((images, raw_X), axis=0)\n",
        "      labels = np.concatenate((labels, raw_y), axis=0)\n",
        "      X = np.concatenate((X, proc_X), axis=0)\n",
        "      y = np.concatenate((y, proc_y), axis=0)\n",
        "  return images, labels, X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dDRK2mSLJ6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generamos las imagenes y los outputs\n",
        "images, labels, X, y = read_data(data[data['figure'] == 'a1'])\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bKQeuVNwuoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mostramos una imagen con el punto de la figura marcado\n",
        "def show_image(image, point=None):\n",
        "  if point is not None:\n",
        "    cv2_imshow(cv2.circle(cv2.cvtColor(image[:, :, 0], cv2.COLOR_GRAY2BGR), (int(point[0]), int(point[1])), 3, (0, 0, 255), -1))\n",
        "\n",
        "show_image(images[196], labels[196])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86DyfgfNebCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "\n",
        "# Creamos el modelo\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  model.add(Conv2D(6, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(12, (3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(24, (3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(2))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljd_C2O1gIcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(X, y, test_size=test_dataset_size) # Creamos los datasets de train y test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNTu6RLwjQS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compilamos y entrenamos el modelo\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}