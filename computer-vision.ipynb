{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Test.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenieto/computer-vision/blob/preprocesado-interactivo/computer-vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nzKF921nSpb",
        "colab_type": "text"
      },
      "source": [
        "Trabajo M0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuG171gUnSpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Montamos Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!unzip -o \"/content/drive/My Drive/Datasets/computer-vision-M2.zip\" -d /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8WL4YNeGAkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importamos librerias\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhYCoKhyGqi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definimos variables\n",
        "items_path = '/content/computer-vision-M2/anotaciones_itemsEvaluables_v3.csv'\n",
        "quality_path = '/content/computer-vision-M2/anotacionCalidadCopia.csv'\n",
        "images_path = '/content/computer-vision-M2/dataset2'\n",
        "min_quality = 4\n",
        "pattern = 'a4'\n",
        "IMAGE_CHANNELS = 3\n",
        "IMAGE_SIZE = (128, 128, IMAGE_CHANNELS)\n",
        "test_dataset_size = 0.25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz1nGW1upVDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funciones para leer los datos\n",
        "\n",
        "def remove_spaces(data, keys=None):\n",
        "    if keys is None:\n",
        "        keys = data.keys()\n",
        "    for key in keys:\n",
        "        data[key] = data[key].apply(str.replace, args=(' ', ''))\n",
        "\n",
        "def read_csv_data():\n",
        "  quality_data = pd.read_csv(quality_path, sep=';', names=['image', 'quality'], skipinitialspace=True)\n",
        "  items_data = pd.read_csv(items_path, sep=';', names=['dir', 'image', 'figure', 'coords'], index_col=False, skipinitialspace=True)\n",
        "  remove_spaces(items_data)\n",
        "  remove_spaces(quality_data, keys=['image'])\n",
        "  merged_data = pd.merge(items_data, quality_data, how='left', left_on='image', right_on='image')\n",
        "  merged_data = merged_data[merged_data['quality'] >= min_quality]\n",
        "  return merged_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hvEx6y4Idud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Leemos los datos\n",
        "data = read_csv_data()\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0GLzUrYKBlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inicializamos una intancia scaler\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "# Generar coordenadas\n",
        "def generate_coords(row, pattern):\n",
        "  flat = np.array([int(s) for s in re.findall('\\d+', row['coords'])]) # Parsea los números en el texto\n",
        "  mat = flat.reshape((-1, 2)) # Reagrupa las coordenadas en grupos de dos\n",
        "  valid = True\n",
        "  if pattern == 'a1':\n",
        "    # La mayoría tienen 1 punto\n",
        "    n_points = 1\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a2':\n",
        "    # Demasiada variación, de momento lo ignoramos\n",
        "    valid = False\n",
        "  elif pattern == 'a3':\n",
        "    # Todas tienen 1 punto\n",
        "    n_points = 1\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a4':\n",
        "    # Hay muchas con 2 puntos\n",
        "    n_points = 2\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a5':\n",
        "    # Hay suficientes imágnes con 2 puntos\n",
        "    n_points = 2\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a6':\n",
        "    # De momento lo ignoramos, demasiada variación\n",
        "    valid = False\n",
        "  elif pattern == 'a7':\n",
        "    # Hay muchas con 2 puntos\n",
        "    n_points = 2\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a8':\n",
        "    # Hay muchas con 2 puntos\n",
        "    n_points = 2\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a9':\n",
        "    # De momento lo ignoramos, demasiada variación\n",
        "    valid = False\n",
        "  elif pattern == 'a10':\n",
        "    # necesitamos 2 puntos, cogemos siempre el primero y el ultimo punto\n",
        "    n_points = 2\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = np.array([mat[0], mat[-1]])\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a11':\n",
        "    # todos tienen 1 punto\n",
        "    n_points = 1\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a12':\n",
        "    # este patron no tiene suficientes datos\n",
        "    valid = False\n",
        "  elif pattern == 'a13':\n",
        "    # el CSV se ha modificado a mano para que siempre haya 3 puntos\n",
        "    n_points = 3\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a14':\n",
        "    # todos tienen 1 punto\n",
        "    n_points = 1\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a15':\n",
        "    # necesitamos 2 puntos, cogemos siempre el primero y el ultimo punto\n",
        "    n_points = 2\n",
        "    if mat.shape[0] >= n_points:\n",
        "      mat = np.array([mat[0], mat[-1]])\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a16':\n",
        "    # necesitamos 2 puntos, cogemos siempre el primero y el ultimo punto\n",
        "    n_points = 2\n",
        "    if mat.shape[0] >= n_points:\n",
        "      mat = np.array([mat[0], mat[-1]])\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a17':\n",
        "    # todos tienen 1 punto\n",
        "    n_points = 1\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a18':\n",
        "    # necesitamos 2 puntos, cogemos siempre el primero y el ultimo punto\n",
        "    n_points = 2\n",
        "    if mat.shape[0] >= n_points:\n",
        "      mat = np.array([mat[0], mat[-1]])\n",
        "    else:\n",
        "      valid = False\n",
        "  return mat, valid\n",
        "\n",
        "# Funcion para leer una imagen y sus coordenadas\n",
        "def read_sample(row, pattern='a1'):\n",
        "  # Leer imagenes procesadas\n",
        "  path = os.path.join(images_path, 'grafos_' + row['dir'] + '_limpiezaManual', 'grafo_' + row['image'] + '.png')\n",
        "  raw_X = cv2.imread(path, 0)\n",
        "  raw_y = None\n",
        "  proc_X = None\n",
        "  proc_y = None\n",
        "  if raw_X is not None: # TODO: algunas imagenes no existen\n",
        "    shape = raw_X.shape\n",
        "    raw_X_1 = raw_X[:shape[0]//2, :shape[1]//2] # Imagen original\n",
        "    raw_X_2 = raw_X[:shape[0]//2, shape[1]//2:] # Imagen original invertida\n",
        "    raw_X_3 = raw_X[shape[0]//2:, :shape[1]//2] # Imagen de grafos detalle alto\n",
        "    raw_X_4 = raw_X[shape[0]//2:, shape[1]//2:] # Imagen de grafos detalle bajo\n",
        "    subimage_shape = raw_X_1.shape\n",
        "    raw_X_1 = cv2.resize(raw_X_1, dsize=(IMAGE_SIZE[0], IMAGE_SIZE[1]))\n",
        "    raw_X_2 = cv2.resize(raw_X_2, dsize=(IMAGE_SIZE[0], IMAGE_SIZE[1]))\n",
        "    raw_X_3 = cv2.resize(raw_X_3, dsize=(IMAGE_SIZE[0], IMAGE_SIZE[1]))\n",
        "    raw_X_4 = cv2.resize(raw_X_4, dsize=(IMAGE_SIZE[0], IMAGE_SIZE[1]))\n",
        "    proc_X_1 = scaler.fit_transform(raw_X_1) # Opción más simple: raw_X_1 / 255\n",
        "    proc_X_2 = scaler.fit_transform(raw_X_2) # Opción más simple: raw_X_2 / 255\n",
        "    proc_X_3 = scaler.fit_transform(raw_X_3) # Opción más simple: raw_X_3 / 255\n",
        "    proc_X_4 = scaler.fit_transform(raw_X_4) # Opción más simple: raw_X_4 / 255\n",
        "    if IMAGE_CHANNELS == 1:\n",
        "      raw_X = raw_X_2 # Sólo se usa la imagen original invertida\n",
        "      proc_X = proc_X_2\n",
        "    elif IMAGE_CHANNELS == 2:\n",
        "      raw_X = np.stack((raw_X_2, raw_X_3), axis=-1) # Se usa imagen original invertida + grafos alto detalle\n",
        "      proc_X = np.stack((proc_X_2, proc_X_3), axis=-1)\n",
        "    elif IMAGE_CHANNELS == 3:\n",
        "      raw_X = np.stack((raw_X_2, raw_X_3, raw_X_4), axis=-1) # Se usa imagen original invertida + grafos alto detalle + grafos bajo detalle\n",
        "      proc_X = np.stack((proc_X_2, proc_X_3, proc_X_4), axis=-1)\n",
        "    raw_X = np.expand_dims(raw_X, axis=0)\n",
        "    proc_X = np.expand_dims(proc_X, axis=0)\n",
        "    # Leer coordenadas\n",
        "    mat, valid = generate_coords(row, pattern)\n",
        "    if valid:\n",
        "      raw_y = (mat * np.array([2 * IMAGE_SIZE[0] / subimage_shape[0], 2 * IMAGE_SIZE[1] / subimage_shape[1]]))\n",
        "      proc_y = raw_y / np.array([IMAGE_SIZE[0], IMAGE_SIZE[1]])\n",
        "      raw_y = np.expand_dims(raw_y.flatten(), axis=0)\n",
        "      proc_y = np.expand_dims(proc_y.flatten(), axis=0)\n",
        "  return raw_X, raw_y, proc_X, proc_y\n",
        "\n",
        "# Funcion que devuelve las imagenes y las coordenadas\n",
        "def read_data(data, pattern):\n",
        "  data = data[data['figure'] == pattern]\n",
        "  firstIteration = True\n",
        "  for _, row in data.iterrows():\n",
        "    raw_X, raw_y, proc_X, proc_y = read_sample(row, pattern)\n",
        "    if raw_X is not None and raw_y is not None and proc_y is not None:\n",
        "      if firstIteration == True:\n",
        "        images = raw_X\n",
        "        labels = raw_y\n",
        "        X = proc_X\n",
        "        y = proc_y\n",
        "        firstIteration = False\n",
        "      else:\n",
        "        images = np.concatenate((images, raw_X), axis=0)\n",
        "        labels = np.concatenate((labels, raw_y), axis=0)\n",
        "        X = np.concatenate((X, proc_X), axis=0)\n",
        "        y = np.concatenate((y, proc_y), axis=0)\n",
        "  return images, labels, X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dDRK2mSLJ6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generamos las imagenes y los outputs\n",
        "images, labels, X, y = read_data(data, pattern)\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bKQeuVNwuoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mostramos una imagen con el punto de la figura marcado\n",
        "def show_image(image, point=None):\n",
        "  if point is not None:\n",
        "    im_color = cv2.cvtColor(image[:, :, 0], cv2.COLOR_GRAY2BGR)\n",
        "    for i in range(point.shape[0]//2):\n",
        "      im_color = cv2.circle(im_color, (int(point[2*i]), int(point[2*i+1])), 3, (0, 0, 255), -1)\n",
        "    cv2_imshow(im_color)\n",
        "\n",
        "show_image(images[25], labels[25])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86DyfgfNebCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "\n",
        "# Creamos el modelo\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  \n",
        "  model.add(Conv2D(24, (3, 3), activation='relu', input_shape=IMAGE_SIZE))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(48, (3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(96, (3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(y.shape[1], activation='relu'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljd_C2O1gIcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(X, y, test_size=test_dataset_size) # Creamos los datasets de train y test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNTu6RLwjQS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "\n",
        "def initializeCallbacks():\n",
        "    filepath_mdl = 'model.h5'\n",
        "    checkpoint = ModelCheckpoint(filepath_mdl, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    tensorboard = TensorBoard(log_dir='./logs', batch_size=8, write_graph=True, write_images=True)\n",
        "    earlystopping = EarlyStopping(patience=10, verbose=1)\n",
        "    return [checkpoint, tensorboard, earlystopping]\n",
        "\n",
        "# Compilamos y entrenamos el modelo\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "model.summary()\n",
        "output = model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=50, verbose=1, callbacks=initializeCallbacks())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnpgfh6jm6AQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fw-R_jmmU94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start TensorBoard within the notebook using magics\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Gf9UItJhSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluar resultado\n",
        "prediction = model.predict(np.expand_dims(X[0], axis=0)) # Predict first image\n",
        "prediction = (prediction.reshape((-1, 2)) * np.array([IMAGE_SIZE[0], IMAGE_SIZE[1]])).reshape((1, -1)) # Invert normalization\n",
        "show_image(images[0], prediction[0])\n",
        "show_image(images[0], labels[0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}