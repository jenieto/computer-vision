{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Test.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenieto/computer-vision/blob/k-fold-cross-validation/computer-vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nzKF921nSpb",
        "colab_type": "text"
      },
      "source": [
        "Trabajo M0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuG171gUnSpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Montamos Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!unzip -o \"/content/drive/My Drive/Datasets/computer-vision-M2.zip\" -d /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8WL4YNeGAkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importamos librerias\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import re\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhYCoKhyGqi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definimos variables\n",
        "items_path = '/content/computer-vision-M2/anotaciones_itemsEvaluables_v4.csv'\n",
        "quality_path = '/content/computer-vision-M2/anotacionCalidadCopia.csv'\n",
        "images_path = '/content/computer-vision-M2/dataset2'\n",
        "min_quality = 4\n",
        "pattern = 'a13'\n",
        "IMAGE_CHANNELS = 1\n",
        "IMAGE_SIZE = (128, 128, IMAGE_CHANNELS)\n",
        "test_dataset_size = 0.20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz1nGW1upVDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Funciones para leer los datos\n",
        "\n",
        "def remove_spaces(data, keys=None):\n",
        "    if keys is None:\n",
        "        keys = data.keys()\n",
        "    for key in keys:\n",
        "        data[key] = data[key].apply(str.replace, args=(' ', ''))\n",
        "\n",
        "def read_csv_data():\n",
        "  quality_data = pd.read_csv(quality_path, sep=';', names=['image', 'quality'], skipinitialspace=True)\n",
        "  items_data = pd.read_csv(items_path, sep=';', names=['dir', 'image', 'figure', 'coords', 'valid'], index_col=False, skipinitialspace=True)\n",
        "  # remove_spaces(items_data)\n",
        "  remove_spaces(quality_data, keys=['image'])\n",
        "  merged_data = pd.merge(items_data, quality_data, how='left', left_on='image', right_on='image')\n",
        "  merged_data = merged_data[merged_data['quality'] >= min_quality]\n",
        "  merged_data = merged_data[merged_data['valid'] == True]\n",
        "  return merged_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hvEx6y4Idud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Leemos los datos\n",
        "data = read_csv_data()\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0GLzUrYKBlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inicializamos una intancia scaler\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "# Generar coordenadas\n",
        "def generate_coords(row, pattern):\n",
        "  flat = np.array([int(s) for s in re.findall('\\d+', row['coords'])]) # Parsea los números en el texto\n",
        "  mat = flat.reshape((-1, 2)) # Reagrupa las coordenadas en grupos de dos\n",
        "  valid = True\n",
        "  if pattern == 'a1':\n",
        "    # La mayoría tienen 1 punto\n",
        "    n_points = 1\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a2':\n",
        "    # Demasiada variación, de momento lo ignoramos\n",
        "    valid = False\n",
        "  elif pattern == 'a3':\n",
        "    # Todas tienen 1 punto\n",
        "    n_points = 1\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a4':\n",
        "    # necesitamos 2 puntos, cogemos siempre el primero y el ultimo punto\n",
        "    n_points = 2\n",
        "    if mat.shape[0] >= n_points:\n",
        "      mat = np.array([mat[0], mat[-1]])\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a5':\n",
        "    # Hay suficientes imágnes con 2 puntos\n",
        "    n_points = 2\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a6':\n",
        "    # De momento lo ignoramos, demasiada variación\n",
        "    valid = False\n",
        "  elif pattern == 'a7':\n",
        "    # Hay muchas con 2 puntos\n",
        "    n_points = 2\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a8':\n",
        "    # Hay muchas con 2 puntos\n",
        "    n_points = 2\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a9':\n",
        "    # De momento lo ignoramos, demasiada variación\n",
        "    valid = False\n",
        "  elif pattern == 'a10':\n",
        "    # necesitamos 2 puntos, cogemos siempre el primero y el ultimo punto\n",
        "    n_points = 2\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = np.array([mat[0], mat[-1]])\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a11':\n",
        "    # todos tienen 1 punto\n",
        "    n_points = 1\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a12':\n",
        "    # este patron no tiene suficientes datos\n",
        "    valid = False\n",
        "  elif pattern == 'a13':\n",
        "    # el CSV se ha modificado a mano para que siempre haya 3 puntos\n",
        "    n_points = 3\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a14':\n",
        "    # todos tienen 1 punto\n",
        "    n_points = 1\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a15':\n",
        "    # necesitamos 2 puntos, cogemos siempre el primero y el ultimo punto\n",
        "    n_points = 2\n",
        "    if mat.shape[0] >= n_points:\n",
        "      mat = np.array([mat[0], mat[-1]])\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a16':\n",
        "    # necesitamos 2 puntos, cogemos siempre el primero y el ultimo punto\n",
        "    n_points = 2\n",
        "    if mat.shape[0] >= n_points:\n",
        "      mat = np.array([mat[0], mat[-1]])\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a17':\n",
        "    # todos tienen 1 punto\n",
        "    n_points = 1\n",
        "    if mat.shape[0] == n_points:\n",
        "      mat = mat[:n_points, :]\n",
        "    else:\n",
        "      valid = False\n",
        "  elif pattern == 'a18':\n",
        "    # necesitamos 2 puntos, cogemos siempre el primero y el ultimo punto\n",
        "    n_points = 2\n",
        "    if mat.shape[0] >= n_points:\n",
        "      mat = np.array([mat[0], mat[-1]])\n",
        "    else:\n",
        "      valid = False\n",
        "  return mat, valid\n",
        "\n",
        "# Funcion para leer una imagen y sus coordenadas\n",
        "def read_sample(row, pattern='a1'):\n",
        "  # Leer imagenes procesadas\n",
        "  path = os.path.join(images_path, 'grafos_' + row['dir'] + '_limpiezaManual', 'grafo_' + row['image'] + '.png')\n",
        "  raw_X = cv2.imread(path, 0)\n",
        "  raw_y = None\n",
        "  proc_X = None\n",
        "  proc_y = None\n",
        "  if raw_X is not None: # TODO: algunas imagenes no existen\n",
        "    shape = raw_X.shape\n",
        "    raw_X_1 = raw_X[:shape[0]//2, :shape[1]//2] # Imagen original\n",
        "    raw_X_2 = raw_X[:shape[0]//2, shape[1]//2:] # Imagen original invertida\n",
        "    raw_X_3 = raw_X[shape[0]//2:, :shape[1]//2] # Imagen de grafos detalle alto\n",
        "    raw_X_4 = raw_X[shape[0]//2:, shape[1]//2:] # Imagen de grafos detalle bajo\n",
        "    subimage_shape = raw_X_2.shape\n",
        "    raw_X_1 = cv2.resize(raw_X_1, dsize=(IMAGE_SIZE[0], IMAGE_SIZE[1]))\n",
        "    raw_X_2 = cv2.resize(raw_X_2, dsize=(IMAGE_SIZE[0], IMAGE_SIZE[1]))\n",
        "    raw_X_3 = cv2.resize(raw_X_3, dsize=(IMAGE_SIZE[0], IMAGE_SIZE[1]))\n",
        "    raw_X_4 = cv2.resize(raw_X_4, dsize=(IMAGE_SIZE[0], IMAGE_SIZE[1]))\n",
        "    proc_X_1 = scaler.fit_transform(raw_X_1) # Opción más simple: raw_X_1 / 255\n",
        "    proc_X_2 = scaler.fit_transform(raw_X_2) # Opción más simple: raw_X_2 / 255\n",
        "    proc_X_3 = scaler.fit_transform(raw_X_3) # Opción más simple: raw_X_3 / 255\n",
        "    proc_X_4 = scaler.fit_transform(raw_X_4) # Opción más simple: raw_X_4 / 255\n",
        "    if IMAGE_CHANNELS == 1:\n",
        "      raw_X = np.expand_dims(raw_X_2, axis=-1) # Sólo se usa la imagen original invertida\n",
        "      proc_X = np.expand_dims(proc_X_2, axis=-1)\n",
        "    elif IMAGE_CHANNELS == 2:\n",
        "      raw_X = np.stack((raw_X_2, raw_X_3), axis=-1) # Se usa imagen original invertida + grafos alto detalle\n",
        "      proc_X = np.stack((proc_X_2, proc_X_3), axis=-1)\n",
        "    elif IMAGE_CHANNELS == 3:\n",
        "      raw_X = np.stack((raw_X_2, raw_X_3, raw_X_4), axis=-1) # Se usa imagen original invertida + grafos alto detalle + grafos bajo detalle\n",
        "      proc_X = np.stack((proc_X_2, proc_X_3, proc_X_4), axis=-1)\n",
        "    raw_X = np.expand_dims(raw_X, axis=0)\n",
        "    proc_X = np.expand_dims(proc_X, axis=0)\n",
        "    # Leer coordenadas\n",
        "    mat, valid = generate_coords(row, pattern)\n",
        "    if valid:\n",
        "      raw_y = (mat * np.array([2 * IMAGE_SIZE[1] / subimage_shape[1], 2 * IMAGE_SIZE[0] / subimage_shape[0]]))\n",
        "      proc_y = raw_y / np.array([IMAGE_SIZE[1], IMAGE_SIZE[0]])\n",
        "      raw_y = np.expand_dims(raw_y.flatten(), axis=0)\n",
        "      proc_y = np.expand_dims(proc_y.flatten(), axis=0)\n",
        "  return raw_X, raw_y, proc_X, proc_y\n",
        "\n",
        "# Funcion que devuelve las imagenes y las coordenadas\n",
        "def read_data(data, pattern):\n",
        "  data = data[data['figure'] == pattern]\n",
        "  firstIteration = True\n",
        "  for _, row in data.iterrows():\n",
        "    raw_X, raw_y, proc_X, proc_y = read_sample(row, pattern)\n",
        "    if raw_X is not None and raw_y is not None and proc_y is not None:\n",
        "      if firstIteration == True:\n",
        "        images = raw_X\n",
        "        labels = raw_y\n",
        "        X = proc_X\n",
        "        # y = proc_y\n",
        "        y = raw_y\n",
        "        firstIteration = False\n",
        "      else:\n",
        "        images = np.concatenate((images, raw_X), axis=0)\n",
        "        labels = np.concatenate((labels, raw_y), axis=0)\n",
        "        X = np.concatenate((X, proc_X), axis=0)\n",
        "        #y = np.concatenate((y, proc_y), axis=0)\n",
        "        y = np.concatenate((y, raw_y), axis=0)\n",
        "  return images, labels, X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dDRK2mSLJ6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generamos las imagenes y los outputs\n",
        "images, labels, X, y = read_data(data, pattern)\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bKQeuVNwuoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mostramos una imagen con el punto de la figura marcado\n",
        "def show_image(image, point=None):\n",
        "  if point is not None:\n",
        "    im_color = cv2.cvtColor(image[:, :, 0], cv2.COLOR_GRAY2BGR)\n",
        "    for i in range(point.shape[0]//2):\n",
        "      im_color = cv2.circle(im_color, (int(point[2*i]), int(point[2*i+1])), 3, (0, 0, 255), -1)\n",
        "    cv2_imshow(im_color)\n",
        "\n",
        "show_image(images[20], labels[20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86DyfgfNebCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Creamos el modelo\n",
        "def create_model():  \n",
        "  model = tf.keras.models.Sequential() # Create the model\n",
        "  network_type = 1\n",
        "\n",
        "  if network_type == 0:\n",
        "    conv = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling='avg') #Load the MobileNet v2 model\n",
        "    # for layer in conv.layers[:-15]: # Freeze the layers except the last 3 layers\n",
        "    #   layer.trainable = False\n",
        "    # for layer in conv.layers: # Check the trainable status of the individual layers\n",
        "    #   print(layer, layer.trainable)\n",
        "    model.add(conv) # Add the convolutional base model\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    # model.add(Dropout(0.1))\n",
        "    model.add(Dense(y.shape[1], activation='relu'))\n",
        "    \n",
        "  elif network_type == 1:\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=IMAGE_SIZE))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(y.shape[1], activation='relu', kernel_regularizer=l2(0.001)))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljd_C2O1gIcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = create_model()\n",
        "# train_images, test_images, train_labels, test_labels = train_test_split(X, y, test_size=test_dataset_size) # Creamos los datasets de train y test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNTu6RLwjQS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# custom metric para distancia euclidea\n",
        "def eu(y_true, y_pred):\n",
        "  n_points = int(y_true[0].shape[0] / 2)\n",
        "  distance = 0\n",
        "  for n in range(n_points):\n",
        "    distance += K.sqrt(K.square(y_pred[0][n] - y_true[0][n]) + K.square(y_pred[0][n+1] - y_true[0][n+1]))\n",
        "  return distance\n",
        "\n",
        "def initializeCallbacks():\n",
        "    filepath_mdl = 'model.h5'\n",
        "    checkpoint = ModelCheckpoint(filepath_mdl, monitor='val_loss', verbose=1, save_best_only=True) # Va guardando los pesos tras cada época\n",
        "    log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, write_images=True) # Para graficado de las estadísticas durante el entrenamiento\n",
        "    earlystopping = EarlyStopping(patience=20, verbose=1) # Detiene el entrenamiento prematuramente si validation accuracy lleva sin aumentar varias épocas\n",
        "    return [checkpoint, tensorboard, earlystopping]\n",
        "\n",
        "# define 5-fold cross validation test harness\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "for train, test in kfold.split(X, y):\n",
        "  # Creamos el modelo\n",
        "  model = create_model()\n",
        "  # Compilamos y entrenamos el modelo\n",
        "  model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=[eu  ])\n",
        "  # model.summary()\n",
        "  output = model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=100, verbose=1, callbacks=initializeCallbacks())\n",
        "  scores = model.evaluate(X[test], y[test], verbose=0)\n",
        "  print(f\"{model.metrics_names[1]}: {scores[1]*100:.2f}\")\n",
        "  cvscores.append(scores[1] * 100)\n",
        "print(f'{np.mean(cvscores):.2f} (+/- {np.std(cvscores):.2f})')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnpgfh6jm6AQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fw-R_jmmU94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start TensorBoard within the notebook using magics\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Gf9UItJhSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# Evaluar resultado\n",
        "def show_test_image(image, point=None):\n",
        "  if point is not None:\n",
        "    x = image[:, :, 0].astype('float32') * 255\n",
        "    image = cv2.cvtColor(x, cv2.COLOR_GRAY2BGR)\n",
        "    image_with_point = image\n",
        "    for i in range(point.shape[0]//2):\n",
        "      image_with_point = cv2.circle(image, (int(point[2*i]), int(point[2*i+1])), 3, (255, 0, 0), -1)\n",
        "    # cv2_imshow(image2)\n",
        "    return image_with_point\n",
        "\n",
        "\n",
        "def plot_image_matrix(images=[], coords=[]):\n",
        "    columns = 3\n",
        "    rows = math.ceil(len(images) / columns)\n",
        "    fig, ax = plt.subplots(nrows=rows, ncols=columns, figsize=(10, 10))\n",
        "    \n",
        "    row = 0\n",
        "    col = 0\n",
        "    i = 0\n",
        "    for img in images:\n",
        "      image_with_points = show_test_image(img, coords[i])\n",
        "      ax[row][col].imshow(image_with_points, cmap='gray', vmin=0, vmax=255)\n",
        "      i += 1\n",
        "      col += 1\n",
        "      if col >= columns:\n",
        "        col = 0\n",
        "        row += 1\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "model.load_weights(\"model.h5\") # Cargamos pesos guardados\n",
        "\n",
        "images = []\n",
        "coords = []\n",
        "for i in range(0, 9):\n",
        "  image = test_images[i]\n",
        "  prediction = model.predict(np.expand_dims(image, axis=0))\n",
        "  images.append(image)\n",
        "  coords.append(prediction[0])\n",
        "  print(f'Predicted coordinates: {prediction[0]} -- Real coordinates: {test_labels[i]}')\n",
        "plot_image_matrix(images, coords)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}